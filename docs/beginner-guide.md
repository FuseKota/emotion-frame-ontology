# EFO-PlutchikDyad 実験：初心者向けガイド

> **対象読者**: プログラミングや統計の専門知識がなくても、本プロジェクトの「何をやっているか」「何がわかったか」を理解したい方

---

## 1. このプロジェクトは何？

### 一言でいうと

**「テキストから複合感情を自動で読み取る仕組み」を作り、それがちゃんと動くか検証した**プロジェクトです。

### もう少し詳しく

人間の感情は単純ではありません。「嬉しいけど不安」「怒りつつも期待している」のように、複数の感情が同時に存在します。

心理学者の Robert Plutchik は、基本感情の組み合わせで複合感情を定義しました：

```
愛（Love）     = 喜び（Joy） + 信頼（Trust）
楽観（Optimism）= 期待（Anticipation） + 喜び（Joy）
軽蔑（Contempt）= 嫌悪（Disgust） + 怒り（Anger）
不賛成（Disapproval）= 驚き（Surprise） + 悲しみ（Sadness）
```

このプロジェクトでは：

1. テキストから **8 つの基本感情のスコア** を AI で計算
2. そのスコアを組み合わせて **10 種類の複合感情のスコア** を算出
3. 算出したスコアが **人間の判断とどれくらい一致するか** を検証

---

## 2. どうやって複合感情を計算するの？

### Step 1: テキストから基本感情を読み取る

AI モデル（RoBERTa）にテキストを入力すると、28 種類の感情スコアが出力されます。
これを Plutchik の 8 基本感情に変換します。

```
入力:  「友達が突然パーティーを開いてくれた！」
    ↓ AI 分析
出力:  Joy=0.8, Trust=0.6, Surprise=0.7, ...（8 感情のスコア）
```

各スコアは 0〜1 の範囲で、1 に近いほどその感情が強いことを意味します。

### Step 2: 複合感情のスコアを計算する

2 つの基本感情のスコアから、複合感情のスコアを 1 つの数値にまとめます。

例えば Love = Joy + Trust で、Joy=0.8、Trust=0.3 のとき：

```
Love のスコア = min(0.8, 0.3) = 0.3
                ↑ 2つのうち小さい方を取る
```

**なぜ小さい方？**
「チェーンの強さは一番弱い環で決まる」という考え方です。
いくら Joy が高くても Trust が低ければ、それは Love とは言いにくい — という直感に基づいています。

### Step 3: 知識グラフ（オントロジー）に変換する

計算結果をコンピュータが理解できる形式（RDF / 知識グラフ）に変換します。
これにより、「なぜこのテキストを Love と判定したか」を機械的に説明できます。

```
テキスト#42 → 感情: Love
  ├─ 根拠1: Joy スコア = 0.8（証拠: "パーティー" → admiration, joy）
  └─ 根拠2: Trust スコア = 0.3（証拠: "友達" → caring, trust）
```

---

## 3. 検証：ちゃんと動いているか？

「AI が出した結果が正しいか」を検証するのが、このプロジェクトの核心です。
以下の 4 つの角度から検証しました。

### 検証 1: 外部データとの一致度（Step 7）

**やったこと**: SemEval-2018 という「人間が感情の強さを数値で付けたデータセット」と比較

**わかったこと**:

| 複合感情 | 一致度（Spearman ρ） | 解釈 |
|---------|-------------------|------|
| Disapproval（不賛成） | **+0.636** | かなり強い一致 |
| Contempt（軽蔑） | **+0.509** | 中程度〜強い一致 |
| Love（愛） | **+0.349** | 中程度の一致 |
| Optimism（楽観） | **+0.165** | 弱いが統計的に有意 |

> **Spearman ρ の読み方**:
> - 0 = 全く関係なし、1 = 完璧に一致
> - 0.3 以上で「一定の関連あり」、0.5 以上で「かなり関連あり」
> - 全 4 つが統計的に有意（偶然ではない）

**意味**: AI が計算した複合感情スコアは、人間の感覚とちゃんと連動している。
特に Disapproval と Contempt は高い精度で一致。

### 検証 2: 成分スコアを超える価値があるか？（Step 8）

**疑問**: 「Joy=0.8, Trust=0.3 の 2 つの数字があれば十分で、わざわざ Love=0.3 を計算する意味があるの？」

**やったこと**: Joy と Trust のスコアの影響を統計的に取り除いた上で、
Love スコアが追加の情報を持っているかを偏相関分析で検証

**わかったこと**: 4 つの複合感情すべてで、複合感情スコアは成分だけでは
説明できない追加の情報を持っていた（統計的に有意）

**意味**: 「2 つの基本感情を別々に見る」のと「複合感情として組み合わせる」のとでは、
後者に独自の価値がある。「全体は部分の和ではない」ことを数値で示せた。

### 検証 3: 品質保証（Step 9）

**やったこと**: 知識グラフが壊れていないか、推論の根拠が正しく記録されているかを自動チェック

**わかったこと**:

| チェック項目 | 結果 |
|------------|------|
| データの形式エラー（SHACL 違反） | **0 件** |
| 品質テスト（7 項目） | **全パス** |
| 推論の根拠が記録されているか | **100%** |
| スコアの計算が正しいか | **100%** |

**意味**: 知識グラフの中身は技術的に正しく、すべての推論に「なぜそう判定したか」の根拠がある。

### 検証 4: 計算方法の比較（Step 10）— Ablation Study

**疑問**: 「2 つのスコアを組み合わせるとき、min()（小さい方を取る）が本当に最善？」

**やったこと**: 7 種類の計算方法を試して、人間の判断との一致度を比較

```
例: Joy=0.8, Trust=0.3 のとき

1. Min（現行）        → 0.30  「弱い方に合わせる」
2. Product（掛け算）   → 0.24  「両方高くないとダメ」
3. Geometric Mean      → 0.49  「バランス型」
4. Harmonic Mean       → 0.44  「弱い方を重視しつつ両方見る」
5. Łukasiewicz         → 0.10  「両方 0.5 以上ないとほぼゼロ」
6. Power Mean          → 0.35  「Min に近いが少しマイルド」
7. OWA                 → 0.45  「弱い方メインだけど強い方も少し加味」
```

**わかったこと**:

| 計算方法 | 人間との平均一致度 | 評価 |
|---------|----------------|------|
| **OWA** | **+0.544** | 最も良い |
| Product / Geometric Mean | +0.514 | 良い |
| Harmonic Mean | +0.451 | まあまあ |
| Power Mean | +0.431 | まあまあ |
| **Min（現行）** | **+0.415** | そこそこ |
| Łukasiewicz | +0.204 | 悪い |

**特に Optimism で大きな差**:
- Min: +0.165（弱い一致）→ OWA: +0.519（かなり強い一致）
- Optimism = Anticipation + Joy で、Min だと Joy の情報が捨てられてしまう

**意味**:
- OWA という方法が全体的に最も人間の感覚に近い結果を出す
- ただし、現行の Min にはファジィ論理（Gödel t-norm）という理論的な裏付けがある
- 「理論的な正しさ」と「データでの性能」のトレードオフが存在する
- Łukasiewicz（両方高くないとゼロになる方法）はほとんどのデータでゼロになり不適切

---

## 4. 結果の全体像

```
                     ┌─────────────────────────────┐
                     │  テキスト（約 2,000 件）      │
                     └──────────┬──────────────────┘
                                ↓
                     ┌─────────────────────────────┐
                     │  AI で 8 基本感情スコア算出   │  Step 1–2
                     └──────────┬──────────────────┘
                                ↓
                     ┌─────────────────────────────┐
                     │  10 複合感情スコアを推論      │  Step 3–3b
                     │  （965 件の複合感情を検出）   │
                     └──────────┬──────────────────┘
                                ↓
               ┌────────────────┼────────────────┐
               ↓                ↓                ↓
    ┌──────────────┐  ┌──────────────┐  ┌──────────────┐
    │ 外部妥当性    │  │ 増分価値     │  │ 品質保証     │
    │ ρ=0.17〜0.64 │  │ 4/4 有意     │  │ 全パス       │
    │ 全て有意      │  │              │  │              │
    └──────────────┘  └──────────────┘  └──────────────┘
          Step 7            Step 8            Step 9
               │                │                │
               └────────────────┼────────────────┘
                                ↓
                     ┌─────────────────────────────┐
                     │  集約関数の比較（7 種）       │  Step 10
                     │  → OWA が最良、Min に理論的   │
                     │    裏付けあり                 │
                     └─────────────────────────────┘
```

---

## 5. よくある疑問

### Q: なぜ GoEmotions と SemEval の 2 つのデータを使うの？

**A**: 役割が違います。

- **GoEmotions**（2,000 件）: AI モデルの入力データ。ここから複合感情を計算する
- **SemEval-2018**（7,801 件）: 検証用の外部データ。人間が付けた感情の強さを「正解」として使う

自分で作ったデータで自分を評価すると「自己採点」になってしまうので、
**別のデータで検証する**ことが重要です。

### Q: Spearman ρ って何？

**A**: 2 つの数値の並び順がどれくらい一致しているかを測る指標です。

例：5 人のテストの順位を 2 人の先生が付けたとき
- 先生 A: 田中 1 位、鈴木 2 位、佐藤 3 位
- 先生 B: 田中 1 位、鈴木 2 位、佐藤 3 位
→ 完全一致 → ρ = 1.0

- 先生 A: 田中 1 位、鈴木 2 位、佐藤 3 位
- 先生 B: 佐藤 1 位、鈴木 2 位、田中 3 位
→ 完全に逆 → ρ = -1.0

本プロジェクトでは「AI が付けた複合感情スコアの順位」と「人間が付けた感情の強さの順位」が
どれくらい一致するかを見ています。

### Q: Holm 補正って何？

**A**: たくさんの検定を同時に行うと、偶然「有意」と出てしまう確率が上がります。
例えば 20 回コインを投げて 1 回表が出ても驚かないのと同じです。

Holm 補正は「たくさん検定した分だけ、有意と判定するハードルを上げる」方法です。
これにより、偶然の結果を排除し、本当に意味のある結果だけを報告できます。

### Q: 偏相関って何？

**A**: 「他の要因の影響を取り除いた上での相関」です。

例：アイスクリームの売上と溺死事故は相関しますが、これは「気温」が原因です。
気温の影響を取り除くと、アイスと溺死には直接の関係はありません。

本プロジェクトでは「Joy と Trust の影響を取り除いた上で、Love スコアが
SemEval の強度と相関するか」を調べ、Love スコアに独自の価値があるか検証しています。

### Q: OWA (0.3/0.7) とは？

**A**: Ordered Weighted Average（順序付き重み平均）の略です。

```
OWA = 0.3 × max(成分1, 成分2) + 0.7 × min(成分1, 成分2)
```

弱い方を 70% 重視し、強い方も 30% 考慮します。Min（弱い方だけ見る）と
Average（両方均等に見る）の中間的な方法です。

感情分析の先行研究（Cognitive Computation, 2021）で使用実績があります。

### Q: なぜ Min を使い続けるの？OWA の方が良いのでは？

**A**: これは「理論的な正しさ」と「データでの性能」のトレードオフです。

- **Min の理論的根拠**: ファジィ論理の Gödel t-norm として数学的に定義されている。
  「両方の条件が満たされる程度」を表す標準的な演算子
- **OWA の実験的優位性**: 今回のデータでは人間の判断との一致度が高い

論文では「Min を理論的根拠から採用しつつ、OWA が改善する余地があることを Ablation Study で示した」
という balanced な議論をする予定です。

---

## 6. 生成されるファイル

### データ（`data/experiment/` 内）

| ファイル | 何が入っているか |
|---------|-----------------|
| `goemotion_subset.csv` | 分析対象のテキスト 2,000 件 |
| `classified_scores.jsonl` | 各テキストの 28 感情スコア |
| `plutchik_scores.jsonl` | 各テキストの 8 基本感情スコア |
| `experiment_data.ttl` | 知識グラフ（RDF 形式） |
| `semeval_plutchik_cache.jsonl` | SemEval テキストの感情スコア（キャッシュ） |

### 結果（`output/experiment/` 内）

| ファイル | 何がわかるか |
|---------|------------|
| `semeval_continuous.json` | 外部妥当性の検証結果（Step 7） |
| `incremental_value.json` | 増分価値の検証結果（Step 8） |
| `ontology_qa.json` | 品質保証の検証結果（Step 9） |
| `aggregation_study.json` | 計算方法の比較結果（Step 10） |

### 図（`output/experiment/figures/` 内）

| Fig | ファイル | 何が描かれているか |
|-----|---------|------------------|
| 7 | `semeval_continuous_correlation.png` | 複合感情スコア vs 人間の評価の散布図 |
| 8 | `incremental_value.png` | 3 モデルの説明力比較 |
| 9 | `ontology_qa_dashboard.png` | 品質チェック結果のダッシュボード |
| 10 | `aggregation_comparison.png` | 7 つの計算方法の比較ヒートマップ |

---

## 7. 実行方法

### 前提条件

- Python 3.9 以上
- 必要ライブラリ: `pip install -r requirements-experiment.txt`
- SemEval-2018 データの事前配置（詳細は `docs/current-status.md` 参照）

### 全部まとめて実行

```bash
python -m experiment.run_pipeline --n 2000 --seed 42
```

初回は AI モデルのダウンロードがあるため数分かかります。
2 回目以降はキャッシュにより高速です。

### 特定のステップだけ実行

```bash
# 計算方法の比較だけ実行（数秒で完了）
python -m experiment.step10_aggregation_study

# 特定の図だけ生成
python -m experiment.step6_visualize --only 10
```

---

## 8. 用語集

| 用語 | 説明 |
|------|------|
| **Dyad** | 2 つの基本感情の組み合わせによる複合感情（例: Love = Joy + Trust） |
| **Plutchik** | 感情の輪を提唱した心理学者。8 基本感情を定義 |
| **dyadScore** | 複合感情の強さを表す 0〜1 の数値 |
| **Spearman ρ (rho)** | 順位の一致度を測る相関係数。-1〜+1 |
| **p 値** | 「偶然この結果が出る確率」。小さいほど信頼できる。通常 0.05 未満で有意 |
| **Bootstrap CI** | データからランダムに何度も抽出して推定値のばらつきを算出する方法 |
| **Holm 補正** | 複数の検定で偶然を排除するための調整 |
| **偏相関** | 他の変数の影響を除いた相関 |
| **PR-AUC** | 「陽性の検出精度」を総合的に測る指標。1 に近いほど良い |
| **VIF** | 変数間の重複度。10 を超えると問題とされる |
| **OWA** | Ordered Weighted Average。順序に基づく重み付き平均 |
| **t-norm** | ファジィ論理における「AND」演算の一般化。min() は代表例 |
| **Ablation Study** | 手法の一部を変えて性能への影響を調べる実験 |
| **RDF** | Resource Description Framework。知識をグラフ構造で表現する標準形式 |
| **SHACL** | 知識グラフのデータが正しい形式かを検証するルール |
| **SemEval** | 自然言語処理の国際評価コンペティション |
| **GoEmotions** | Google が公開した 28 感情ラベル付きテキストデータセット |
