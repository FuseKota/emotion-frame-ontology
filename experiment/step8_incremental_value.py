#!/usr/bin/env python3
"""
Step 8: Incremental value verification for dyadScore.

Demonstrates that dyadScore (= min(comp1, comp2)) provides explanatory power
beyond its constituent component scores alone.

Analyses
--------
1. **Partial correlation** + permutation test (primary)
   - dyadScore ↔ intensity | controlling comp1, comp2
2. **OLS regression** (supplementary)
   - Model 1: intensity ~ comp1 + comp2
   - Model 2: intensity ~ comp1 + comp2 + dyadScore
   - Model 3: intensity ~ comp1 + comp2 + comp1*comp2
   - Compares delta-R², F-test, VIF

Generates: output/experiment/incremental_value.json

Usage:
    python -m experiment.step8_incremental_value
"""

import json
from pathlib import Path
from typing import Any, Dict, List, Tuple

import numpy as np
from scipy import stats

from experiment.config import (
    DATA_DIR,
    DYAD_CONSISTENCY_MAP,
    DYADS,
    FOCUS_DYADS,
    N_PERMUTATION,
    OUTPUT_DIR,
)

OUTPUT_FILE = OUTPUT_DIR / "incremental_value.json"
PLUTCHIK_CACHE = DATA_DIR / "semeval_plutchik_cache.jsonl"
SEMEVAL_CACHE_DIR = DATA_DIR / "semeval_cache"

SEMEVAL_EMOTIONS = ["anger", "fear", "joy", "sadness"]


# ---------------------------------------------------------------------------
# Data loading
# ---------------------------------------------------------------------------

def _load_data() -> Tuple[
    List[str],                      # texts
    List[Dict[str, float]],         # plutchik scores
    Dict[str, Dict[str, float]],    # text -> {emo: intensity}
]:
    """Load SemEval plutchik cache and intensity data."""
    # Load Plutchik cache (generated by step7)
    if not PLUTCHIK_CACHE.exists():
        raise FileNotFoundError(
            f"Plutchik cache not found: {PLUTCHIK_CACHE}\n"
            "Run step7_semeval_continuous first."
        )

    texts = []
    plutchik_list = []
    with open(PLUTCHIK_CACHE, encoding="utf-8") as f:
        for line in f:
            rec = json.loads(line)
            texts.append(rec["text"])
            plutchik_list.append(rec["plutchik_scores"])

    # Load SemEval intensity data
    text_to_intensities: Dict[str, Dict[str, float]] = {}
    for emo in SEMEVAL_EMOTIONS:
        cache_path = SEMEVAL_CACHE_DIR / f"semeval_ei_reg_{emo}.jsonl"
        if not cache_path.exists():
            continue
        with open(cache_path, encoding="utf-8") as f:
            for line in f:
                rec = json.loads(line)
                text = rec["text"]
                if text not in text_to_intensities:
                    text_to_intensities[text] = {}
                text_to_intensities[text][emo] = rec["intensity"]

    return texts, plutchik_list, text_to_intensities


# ---------------------------------------------------------------------------
# Partial correlation
# ---------------------------------------------------------------------------

def _partial_corr(
    x: np.ndarray, y: np.ndarray, covariates: np.ndarray,
) -> float:
    """Spearman partial correlation between x and y, controlling for covariates.

    Uses rank-based partial correlation:
    1. Rank-transform x, y, covariates
    2. Regress out covariates from rank(x) and rank(y)
    3. Return Pearson r of residuals
    """
    n = len(x)
    rx = stats.rankdata(x)
    ry = stats.rankdata(y)
    rc = np.column_stack([stats.rankdata(covariates[:, j])
                          for j in range(covariates.shape[1])])

    # Add intercept
    rc_aug = np.column_stack([np.ones(n), rc])

    # OLS residuals
    try:
        beta_x = np.linalg.lstsq(rc_aug, rx, rcond=None)[0]
        beta_y = np.linalg.lstsq(rc_aug, ry, rcond=None)[0]
    except np.linalg.LinAlgError:
        return 0.0

    res_x = rx - rc_aug @ beta_x
    res_y = ry - rc_aug @ beta_y

    denom = np.sqrt(np.sum(res_x**2) * np.sum(res_y**2))
    if denom == 0:
        return 0.0
    return float(np.sum(res_x * res_y) / denom)


def _permutation_test_partial(
    x: np.ndarray, y: np.ndarray, covariates: np.ndarray,
    n_perm: int = N_PERMUTATION,
    rng: np.random.Generator = None,
) -> Tuple[float, float]:
    """Permutation test for partial correlation significance.

    Returns (observed_r, p_value).
    """
    if rng is None:
        rng = np.random.default_rng(42)

    observed = _partial_corr(x, y, covariates)
    count = 0
    for _ in range(n_perm):
        perm_idx = rng.permutation(len(x))
        r_perm = _partial_corr(x[perm_idx], y, covariates)
        if abs(r_perm) >= abs(observed):
            count += 1

    p_val = (count + 1) / (n_perm + 1)
    return observed, p_val


# ---------------------------------------------------------------------------
# OLS regression
# ---------------------------------------------------------------------------

def _ols_results(
    y: np.ndarray, X: np.ndarray, feature_names: List[str],
) -> Dict[str, Any]:
    """Fit OLS and return R², adjusted R², coefficients, and VIF."""
    n, k = X.shape
    X_aug = np.column_stack([np.ones(n), X])

    try:
        beta = np.linalg.lstsq(X_aug, y, rcond=None)[0]
    except np.linalg.LinAlgError:
        return {"error": "singular matrix"}

    y_hat = X_aug @ beta
    ss_res = np.sum((y - y_hat) ** 2)
    ss_tot = np.sum((y - np.mean(y)) ** 2)

    r2 = 1 - ss_res / ss_tot if ss_tot > 0 else 0.0
    adj_r2 = 1 - (1 - r2) * (n - 1) / (n - k - 1) if n > k + 1 else r2

    # VIF for each predictor
    vifs = {}
    for j in range(k):
        others = np.delete(X, j, axis=1)
        others_aug = np.column_stack([np.ones(n), others])
        try:
            beta_j = np.linalg.lstsq(others_aug, X[:, j], rcond=None)[0]
            pred_j = others_aug @ beta_j
            ss_res_j = np.sum((X[:, j] - pred_j) ** 2)
            ss_tot_j = np.sum((X[:, j] - np.mean(X[:, j])) ** 2)
            r2_j = 1 - ss_res_j / ss_tot_j if ss_tot_j > 0 else 0.0
            vifs[feature_names[j]] = 1 / (1 - r2_j) if r2_j < 1.0 else float("inf")
        except np.linalg.LinAlgError:
            vifs[feature_names[j]] = float("inf")

    return {
        "r2": float(r2),
        "adj_r2": float(adj_r2),
        "n": n,
        "k": k,
        "coefficients": {
            name: float(beta[i + 1]) for i, name in enumerate(feature_names)
        },
        "intercept": float(beta[0]),
        "vif": {k: round(v, 2) for k, v in vifs.items()},
        "ss_res": float(ss_res),
    }


def _f_test_nested(
    ss_res_reduced: float, ss_res_full: float,
    df_reduced: int, df_full: int, n: int,
) -> Tuple[float, float]:
    """F-test for nested model comparison.

    Returns (F_statistic, p_value).
    """
    df_diff = df_reduced - df_full
    if df_diff <= 0 or df_full <= 0 or ss_res_full <= 0:
        return 0.0, 1.0
    f_stat = ((ss_res_reduced - ss_res_full) / df_diff) / (ss_res_full / (n - df_full - 1))
    p_val = 1 - stats.f.cdf(f_stat, df_diff, n - df_full - 1)
    return float(f_stat), float(p_val)


# ---------------------------------------------------------------------------
# Holm correction
# ---------------------------------------------------------------------------

def _holm_correction(p_values: List[float]) -> List[float]:
    """Apply Holm-Bonferroni correction."""
    m = len(p_values)
    if m == 0:
        return []
    order = np.argsort(p_values)
    adjusted = np.empty(m)
    for rank, idx in enumerate(order):
        adjusted[idx] = p_values[idx] * (m - rank)
    sorted_adj = adjusted[order]
    for i in range(1, m):
        if sorted_adj[i] < sorted_adj[i - 1]:
            sorted_adj[i] = sorted_adj[i - 1]
    adjusted[order] = sorted_adj
    return [min(float(p), 1.0) for p in adjusted]


# ---------------------------------------------------------------------------
# Main
# ---------------------------------------------------------------------------

def main() -> Path:
    """Run incremental value analysis."""
    print("Step 8: Incremental value analysis (dyadScore vs components)")

    texts, plutchik_list, text_to_intensities = _load_data()
    print(f"  Loaded {len(texts)} texts with Plutchik scores")

    all_p_values: List[float] = []
    pair_keys: List[Tuple[str, str]] = []
    results: Dict[str, Dict[str, Any]] = {}

    for dyad in FOCUS_DYADS:
        related_emotions = DYAD_CONSISTENCY_MAP.get(dyad, [])
        if not related_emotions:
            continue

        e1, e2 = DYADS[dyad]
        dyad_result: Dict[str, Any] = {}

        for semeval_emo in related_emotions:
            # Gather aligned arrays
            d_scores = []
            intensities = []
            c1_scores = []
            c2_scores = []

            for i, text in enumerate(texts):
                intensity = text_to_intensities.get(text, {}).get(semeval_emo)
                if intensity is None:
                    continue
                ps = plutchik_list[i]
                c1 = ps.get(e1, 0.0)
                c2 = ps.get(e2, 0.0)
                d_scores.append(min(c1, c2))
                intensities.append(intensity)
                c1_scores.append(c1)
                c2_scores.append(c2)

            n = len(d_scores)
            if n < 20:
                dyad_result[semeval_emo] = {"n": n, "skipped": True}
                continue

            d_arr = np.array(d_scores)
            i_arr = np.array(intensities)
            c1_arr = np.array(c1_scores)
            c2_arr = np.array(c2_scores)
            covariates = np.column_stack([c1_arr, c2_arr])

            # --- 1. Partial correlation + permutation test ---
            print(f"  {dyad}/{semeval_emo} (n={n}): computing partial correlation...")
            pcorr, p_perm = _permutation_test_partial(
                d_arr, i_arr, covariates, n_perm=N_PERMUTATION,
            )
            all_p_values.append(p_perm)
            pair_keys.append((dyad, semeval_emo))

            check: Dict[str, Any] = {
                "n": n,
                "dyad": dyad,
                "comp1": e1,
                "comp2": e2,
                "semeval_emotion": semeval_emo,
                "partial_corr": float(pcorr),
                "partial_corr_p_perm": float(p_perm),
                "n_permutations": N_PERMUTATION,
            }

            # --- 2. OLS regression (3 models) ---
            # Model 1: intensity ~ comp1 + comp2
            X1 = np.column_stack([c1_arr, c2_arr])
            m1 = _ols_results(i_arr, X1, [e1, e2])

            # Model 2: intensity ~ comp1 + comp2 + dyadScore
            X2 = np.column_stack([c1_arr, c2_arr, d_arr])
            m2 = _ols_results(i_arr, X2, [e1, e2, "dyadScore"])

            # Model 3: intensity ~ comp1 + comp2 + comp1*comp2
            interaction = c1_arr * c2_arr
            X3 = np.column_stack([c1_arr, c2_arr, interaction])
            m3 = _ols_results(i_arr, X3, [e1, e2, f"{e1}*{e2}"])

            # Delta-R² and F-tests
            delta_r2_m2 = m2["r2"] - m1["r2"]
            delta_r2_m3 = m3["r2"] - m1["r2"]

            f_m2, p_f_m2 = _f_test_nested(
                m1["ss_res"], m2["ss_res"],
                m1["k"], m2["k"], n,
            )
            f_m3, p_f_m3 = _f_test_nested(
                m1["ss_res"], m3["ss_res"],
                m1["k"], m3["k"], n,
            )

            check["ols"] = {
                "model1_components": {
                    "r2": m1["r2"], "adj_r2": m1["adj_r2"],
                    "coefficients": m1["coefficients"],
                },
                "model2_dyadscore": {
                    "r2": m2["r2"], "adj_r2": m2["adj_r2"],
                    "coefficients": m2["coefficients"],
                    "vif": m2["vif"],
                    "delta_r2": delta_r2_m2,
                    "f_stat": f_m2, "f_p": p_f_m2,
                },
                "model3_interaction": {
                    "r2": m3["r2"], "adj_r2": m3["adj_r2"],
                    "coefficients": m3["coefficients"],
                    "vif": m3["vif"],
                    "delta_r2": delta_r2_m3,
                    "f_stat": f_m3, "f_p": p_f_m3,
                },
            }

            dyad_result[semeval_emo] = check

        if dyad_result:
            results[dyad] = dyad_result

    # Holm correction on permutation p-values
    adjusted = _holm_correction(all_p_values)
    for (dyad, emo), p_adj in zip(pair_keys, adjusted):
        if dyad in results and emo in results[dyad]:
            results[dyad][emo]["partial_corr_p_holm"] = p_adj

    # Build output
    output: Dict[str, Any] = {
        "focus_dyads": FOCUS_DYADS,
        "n_permutations": N_PERMUTATION,
        "n_tests_holm": len(all_p_values),
        "results": results,
    }

    # Summary table
    summary = []
    for dyad in FOCUS_DYADS:
        if dyad not in results:
            continue
        for emo, res in results[dyad].items():
            if res.get("skipped"):
                continue
            ols = res.get("ols", {})
            m2 = ols.get("model2_dyadscore", {})
            m3 = ols.get("model3_interaction", {})
            summary.append({
                "dyad": dyad,
                "semeval_emotion": emo,
                "n": res["n"],
                "partial_corr": res["partial_corr"],
                "p_perm": res["partial_corr_p_perm"],
                "p_holm": res.get("partial_corr_p_holm"),
                "delta_r2_dyad": m2.get("delta_r2"),
                "delta_r2_interaction": m3.get("delta_r2"),
                "vif_dyadscore": m2.get("vif", {}).get("dyadScore"),
                "f_p_dyad": m2.get("f_p"),
            })
    output["summary_table"] = summary

    # Write
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(output, f, indent=2, ensure_ascii=False)

    print(f"\n  Written to: {OUTPUT_FILE}")

    # Print summary
    print("\n  === Summary (Incremental Value) ===")
    for row in summary:
        sig = "***" if (row["p_holm"] or 1) < 0.001 else (
            "**" if (row["p_holm"] or 1) < 0.01 else (
                "*" if (row["p_holm"] or 1) < 0.05 else ""))
        print(
            f"  {row['dyad']:15s} / {row['semeval_emotion']:8s}  "
            f"partial_r={row['partial_corr']:+.4f}  "
            f"p(Holm)={row['p_holm']:.4f}  "
            f"dR2(dyad)={row['delta_r2_dyad']:+.4f}  "
            f"dR2(inter)={row['delta_r2_interaction']:+.4f}  "
            f"VIF={row['vif_dyadscore']:.1f}  "
            f"{sig}"
        )

    return OUTPUT_FILE


if __name__ == "__main__":
    main()
